{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a354e6d",
   "metadata": {},
   "source": [
    "# Mapreader Workshops 2024"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e640743",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2353861",
   "metadata": {},
   "source": [
    "First check you have the correct version of MapReader: v1.3.2\n",
    "\n",
    "This can be downloaded from pypi using `pip install mapreader==1.3.2` or by checking out the repo at [this commit](https://github.com/Living-with-machines/MapReader/releases/tag/v1.3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0d31f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mapreader\n",
    "assert mapreader.__version__ == '1.3.2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f140c",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "718d06a7",
   "metadata": {},
   "source": [
    "# Annotate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d48c5ab4",
   "metadata": {},
   "source": [
    "Mapreader's ``Annotate`` subpackage is used to annotate images/patches. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11b2287",
   "metadata": {},
   "source": [
    "Today, we will annotate our 100x100 meter patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6201141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfec2076",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Set up your `annotator`\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Annotate.html#annotate-your-images) in docs."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6713049",
   "metadata": {},
   "source": [
    "Before you begin annotating your images, you must tell MapReader:\n",
    "\n",
    "- which labels you'd like to use (``labels``)\n",
    "- who is doing the annotations (``username``)\n",
    "- which task you are running (``task_name``)\n",
    "\n",
    "We will also use the ``sortby=\"mean_pixel_R\"`` option, so that the patches with the highest R pixel intensities are shown first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47bbbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = []\n",
    "# username = \"\"\n",
    "# task_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbee084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotator = Annotator(\n",
    "#     patch_paths=\"./patches_100_meters/*png\",\n",
    "#     parent_paths=\"./maps/*png\",\n",
    "#     metadata_path=\"./maps/metadata.csv\",\n",
    "#     labels=labels,\n",
    "#     username=username,\n",
    "#     task_name=task_name,\n",
    "#     sortby=\"mean_pixel_R\",\n",
    "#     ascending=True,\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "01956c65",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Annotate some patches.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Annotate.html#annotate-your-images) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acfa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.annotate(show_context=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a716b2",
   "metadata": {},
   "source": [
    "As you're progressing through the patches to annotate them, you'll see they are being saved to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f4531",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotator.annotations_file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c21ad32",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6151ccfd",
   "metadata": {},
   "source": [
    "# Classify"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0433e1a7",
   "metadata": {},
   "source": [
    "Mapreader's ``Classify`` subpackage is used to 1) train or fine-tune a CV (computer vision) model to recognize visual features based on your annotated patches and 2) use your model to predict the labels of patches across entire datasets.\n",
    "\n",
    "It contains two important classes:\n",
    "\n",
    "- ``AnnotationsLoader`` - This is used to load and review your annotations and to create datasets and dataloaders which are used to train your model.\n",
    "- ``ClassifierContainer`` - This is used to set up your model, train/fine-tune it using your datasets and to infer labels on new datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d90aa0e9",
   "metadata": {},
   "source": [
    "## Load annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3c5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import AnnotationsLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fbf016",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_images = AnnotationsLoader()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15fef8ac",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Load your annotations. They are saved in your ``\"./annotations/\"`` directory as a ``.csv`` file. You'll need to look in your files to see the exact file name.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#load-and-check-annotations) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8829374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotated_images.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e981c2b3",
   "metadata": {},
   "source": [
    "Running ``annotated_images.labels_map`` will show you you the indexing of your labels. This is so they can be treated as numbers instead of strings in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1366b88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_images.labels_map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ab44301",
   "metadata": {},
   "source": [
    "### Review labels"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4f883e9d",
   "metadata": {},
   "source": [
    "Before training your model, you should check your annotations and ensure you are happy with your labels.\n",
    "\n",
    "This can be done using the ``.review_labels()`` method.\n",
    "\n",
    "For example, to re-label image with ``id: 5``, type \"5\" into the text box, press enter.\n",
    "A text box will show the possible labels (e.g. ``['no_railspace', 'railspace']``). \n",
    "You should then type the new label you'd like for that patch (e.g. ``railspace``) and press enter again to confirm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162a44c1",
   "metadata": {},
   "source": [
    "> _**NOTE**_: type ``exit`` to quit!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f807fc40",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Review your annotations.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#load-and-check-annotations) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553abb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotated_images.review_labels()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "601bb0dc",
   "metadata": {},
   "source": [
    "### Create datasets and dataloaders"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7b5e1897",
   "metadata": {},
   "source": [
    "Before using your annotated images to train your model, you will first need to:\n",
    "\n",
    "1. Split your annotated images into “train”, “val” and and, optionally, “test” datasets.\n",
    "2. Define some transforms which will be applied to your images to ensure your they are in the right format.\n",
    "3. Create dataloaders which can be used to load small batches of your dataset during training/inference and apply the transforms to each image in the batch.\n",
    "\n",
    "> __**NOTE**__: Go to the [Classify/Train](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#prepare-datasets-and-dataloaders) section of the user-guide for more information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "822b70d2",
   "metadata": {},
   "source": [
    "The ``.create_dataloaders()`` method carries out these three steps. \n",
    "\n",
    "> __**NOTE**__: The default train/val/test split, image transforms and sampler will be used if no arguments are supplied to the ``.create_dataloader()`` method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3674d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = annotated_images.create_dataloaders()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a022df6",
   "metadata": {},
   "source": [
    "The code below can be used to see the number of instances of each labelled image in each dataset. \n",
    "\n",
    "This shows the importance of having enough annotations so that each dataset contains a good sample of patches for training, validating and testing your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01de9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_name, dataset in annotated_images.datasets.items():\n",
    "    print(f'Number of instances of each label in \"{set_name}\":')\n",
    "    value_counts = dataset.patch_df[\"label\"].value_counts()\n",
    "    for i in range(len(annotated_images.labels_map)):\n",
    "        print(f\"{annotated_images.labels_map[i]}:\\t{value_counts[i]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df183fc3",
   "metadata": {},
   "source": [
    "## Train your model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "358cd4d7",
   "metadata": {},
   "source": [
    "### Set up your ``my_classifier`` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6276606",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import ClassifierContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cff1f55",
   "metadata": {},
   "source": [
    "The below will make sure that the model training/inference runs as as fast as possible on your machine by using CUDA (GPU) or MPS if they are available.\n",
    "\n",
    "This ``device`` variable can then be fed into the ``ClassifierContainer``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15adb240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ca8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier = ClassifierContainer(\n",
    "    \"resnet18\", \n",
    "    labels_map=annotated_images.labels_map,\n",
    "    dataloaders=dataloaders,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7fee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.add_criterion(\"cross-entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c0c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.initialize_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922b956",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.initialize_scheduler()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "725c1ba2",
   "metadata": {},
   "source": [
    "### Train your model using your \"train\" and \"val\" datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041b7bd5",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Train your model for 10 epochs.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#train-fine-tune-your-model) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e15d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_classifier.train(num_epochs=10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4dc69346",
   "metadata": {},
   "source": [
    "### Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b9bff",
   "metadata": {},
   "source": [
    "MapReader logs a number of common metrics during model training/evaluation and saves them in a dictionary ``my_classifier.metrics``.\n",
    "For example:\n",
    "- loss, calculated using the loss function we defined earlier (i.e. cross-entropy)\n",
    "- f-scores\n",
    "- precision scores\n",
    "- recall scores\n",
    "\n",
    "[This page](https://medium.com/@priyankads/beyond-accuracy-recall-precision-f1-score-roc-auc-6ef2ce097966) provides a good overview of what each of these scores mean.\n",
    "\n",
    "For each metric, a value is logged once per epoch, either on the training dataset (\"train\") or the validation dataset (\"val\").\n",
    "You can see a complete list of the metrics by running ``list(my_classifier.metrics.keys())``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda9f0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(my_classifier.metrics.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7306d9",
   "metadata": {},
   "source": [
    "To plot a metric (or multiple metrics), we can use MapReaders ``plot_metric()`` method, passing the metrics we'd like to plot as the ``y_axis`` arguments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee305a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.plot_metric(\n",
    "    y_axis=[\"epoch_loss_train\", \"epoch_loss_val\"],\n",
    "    y_label=\"loss\",\n",
    "    legends=[\"train loss\", \"valid loss\"],)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cff1d150",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Try visualizing another metric.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#plot-metrics) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0951864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_classifier.plot_metric()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a12831",
   "metadata": {},
   "source": [
    "Alternatively, you can just use ``print`` to view the metrics. \n",
    "\n",
    "For example, the below prints f-scores per class for each class in your labels map. Each number represents the f-score after each pass through the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ad2cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_id, label_name in annotated_images.labels_map.items():\n",
    "    print(label_name, my_classifier.metrics['epoch_fscore_'+str(label_id)+'_val'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9d72f456",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa193808",
   "metadata": {},
   "source": [
    "The \"test\" dataset can be used to test out your model on previously unseen images. \n",
    "\n",
    "As these are already annotated, it makes it easy to understand whether the model is performing as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ec7cb5",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Run inference on the ``\"test\"`` dataset.\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#testing) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065601b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_classifier.inference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dea0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = annotated_images.labels_map[1]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0191a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.show_inference_sample_results(label=label, min_conf=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9078e2",
   "metadata": {},
   "source": [
    "Remember to save your predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2548203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.save_predictions(\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e822ac30",
   "metadata": {},
   "source": [
    "# Infer "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f95630bc",
   "metadata": {},
   "source": [
    "The fine-tuned model can now be used to infer, or predict, the labels of \"unseen\" patches.\n",
    "\n",
    "To show how inference works, we will predict the labels on patches from just one parent image. \n",
    "\n",
    "We will do this by creating a ``subset_patch_df`` from our previously saved ``patch_df.csv``.\n",
    "Our new ``subset_patch_df`` will only contain the information of patches from ``map_75650661.png``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaabe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "patch_df = pd.read_csv(\"./patch_df.csv\", index_col=0)  # load our patch_df.csv file\n",
    "\n",
    "subset_patch_df = patch_df[\n",
    "    patch_df[\"parent_id\"] == \"map_75650661.png\"\n",
    "]  # filter for our chosen parent image\n",
    "subset_patch_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fedfc30",
   "metadata": {},
   "source": [
    "> __**NOTE**__: MapReader can be used to predict the labels on entire datasets and so creating a ``subset_patch_df`` is not needed in most use cases."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b12f48db",
   "metadata": {},
   "source": [
    "### Create a dataset (``infer``) from our ``subset_patch_df``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f482f071",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import PatchDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8757dc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer = PatchDataset(subset_patch_df, transform=\"val\", patch_paths_col=\"image_path\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94eb2966",
   "metadata": {},
   "source": [
    "### Load dataset into ``my_classifier``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.load_dataset(infer, \"infer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "af9e461f",
   "metadata": {},
   "source": [
    "### Run model inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a3f48c",
   "metadata": {},
   "source": [
    "__**YOUR TURN**__: Run inference on your ``\"infer\"`` dataset\n",
    "\n",
    "See [here](https://mapreader.readthedocs.io/en/latest/User-guide/Classify/Train.html#infer-predict) in docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47f6608",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# my_classifier.inference()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6589b",
   "metadata": {},
   "source": [
    "Save results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa7978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_classifier.save_predictions(\"infer\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fd63ec08",
   "metadata": {},
   "source": [
    "### Save results to metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa4808",
   "metadata": {},
   "source": [
    "To add the predictions back into a ``MapImages`` object, we simply need to load our predictions csv file as metadata.\n",
    "\n",
    "Since we have started a new notebook, we can create a new ``MapImages`` object by loading our patches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb25ae",
   "metadata": {},
   "source": [
    "> **NOTE** : Since we've only run inference on one parent map (``map_75650661.png``), we are only going to load patches from that map by regex searching for ``75650661`` in the file names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85dd41cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mapreader import load_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maps = load_patches(\n",
    "    \"./patches_100_meters/*75650661*png\", parent_paths=\"./maps/map_75650661.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734f324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maps.add_metadata(\"./infer_predictions_patch_df.csv\", ignore_mismatch=True, tree_level=\"patch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d734c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maps.add_shape()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0359506",
   "metadata": {},
   "source": [
    "We can use the ``.show_parent()`` method to see how our predictions look on our parent map sheet (``map_75650661.png``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c7f1d2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "my_maps.show_parent(\n",
    "    \"map_75650661.png\",\n",
    "    column_to_plot=\"pred\",\n",
    "    vmin=0,\n",
    "    vmax=1,\n",
    "    alpha=0.5,\n",
    "    patch_border=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1ef19e32",
   "metadata": {},
   "source": [
    "And the ``.convert_images()`` method to save our results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a57626",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_df, patch_df = my_maps.convert_images(save=True, save_format=\"xlsx\") # here we are saving to xlsx so we don't change our \"*.csv\" files from before!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "12eb039a",
   "metadata": {},
   "source": [
    "We can also save our outputs as a ``geojson`` file using the ``.save_patches_to_geojson()`` method.\n",
    "> _**NOTE**_: This will require you to convert your patch coordinates into a polygon format. If these aren't already available, they can be added using the ``.add_patch_polygons()`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97980d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maps.add_patch_polygons()\n",
    "my_maps.save_patches_to_geojson()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8211949a",
   "metadata": {},
   "source": [
    "Beyond MapReader, these outputs can be used to generate interesting visualizations in other tools.\n",
    "\n",
    "For example, here are two visualizations of the rail space data from [our paper]:\n",
    "\n",
    "- https://felt.com/map/MapReader-Launch-Event-map-Urban-Areas-and-Rail-space-9AqftKrvPTlWfwOGkdkCGkD\n",
    "- https://maps.nls.uk/projects/mapreader/index.html#zoom=6.0&lat=56.00000&lon=-4.00000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d356c4f5",
   "metadata": {},
   "source": [
    "# Documentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce9003d1",
   "metadata": {},
   "source": [
    "Please refer to the [MapReader documentation](https://mapreader.readthedocs.io/en/latest/) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5ba55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mapreader_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
